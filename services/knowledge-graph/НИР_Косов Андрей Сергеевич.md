МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ «ТЮМЕНСКИЙ ИНДУСТРИАЛЬНЫЙ УНИВЕРСИТЕТ»

ВЫСШАЯ ШКОЛА ЦИФРОВЫХ ТЕХНОЛОГИЙ

**Пояснительная записка**

**к научно-исследовательской работе**

**Тема НИР:** «Разработка цифрового помощника сотрудника приёмной комиссии»

Выполнил:

обучающийся группы АСОиУб-23-1

А.С Косов /\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Проверил:

канд. пед. наук,

доцент кафедры МиПИТ

О.В Тарханова/ \_\_\_\_\_\_\_\_\_\_\_\_\_

Тюмень 2025

**Содержание**

Введение

…………………………………………………….……………………..…………………....3

1. Анализ и проектирование цифрового помощника сотрудника приёмной комиссии
   1. Анализ предметной области и ключевых факторов зачисления в вузы..........5
   2. Обзор алгоритмов машинного обучения для задач классификации…………6

1.3. Методологии разработки программных систем и жизненные циклы Data Science-проектов........................................................................................................................7

1. Разработка алгоритма прогнозирования вероятности зачисления
   1. Постановка задачи……………………………………………………………….9
   2. Сбор, фильтрация и предварительный анализ данных о поступлении в вуз абитуриентов...........................................................................................................11
   3. Проектирование и создание признаков (Feature Engineering) для модели прогнозирования вероятности поступления…………........................................12
   4. Обучение и сравнительный анализ моделей машинного обучения..................17
2. Внедрение цифрового помощника сотрудника приёмной комиссии
   1. Валидация моделей и выбор оптимальной по метрикам качества....................19
   2. Разработка и тестирование прототипа веб-сервиса для оценки шансов на поступление.............................................................................................................22
   3. Интерпретация модели и анализ значимости факторов зачисления.................23
   4. Результаты и метрики модели…………………………………………………...25

Заключение...........................................................................................................................27

Список используемых источников.....................................................................................28

Приложение A. Глоссарий……………………………………………………………….30

Приложение Б. Исходный код скриптов предобработки данных..................................31
Приложение В. Примеры визуализаций кривых обучения…………………….............32
Приложение Г. Скриншоты интерфейса веб-прототипа.................................................33

**Введение**

Выбор высшего учебного заведения и направления подготовки представляет собой сложную задачу, с которой ежегодно сталкиваются более миллиона абитуриентов, стремящихся зачислиться на бюджетные места. Основная проблема заключается в высоком уровне неопределенности, который сопровождает этот процесс. Абитуриенты часто вынуждены принимать судьбоносные решения, не имея доступа к инструментам для объективной оценки своих реальных возможностей. Они руководствуются зачастую устаревшими или неполными данными о проходных баллах прошлых лет, которые не отражают текущую конкурсную ситуацию. Это приводит к неэффективной оптимизации списка подачи документов и отсутствию персонализированного прогнозирования шансов на поступление, что в условиях высокой конкуренции, достигающей на популярные направления ста и более человек на место, становится критическим фактором.

Актуальность данного исследования обусловлена масштабом проблемы и растущей потребностью в повышении эффективности стратегий подачи документов. Ситуация усугубляется тем, что существующие подходы не в полной мере используют потенциал современных аналитических методов. В то же время развитие и возрастающая доступность технологий машинного обучения открывают новые возможности для создания инструментов аналитической поддержки принятия решений в сфере образования, делая такое решение не только своевременным, но и технически осуществимым.

Новизна предлагаемого подхода состоит в разработке комплексной методологии, которая выходит за рамки простого анализа исторических данных. Планируется создание адаптивной модели, способной учитывать региональные особенности и специфику конкретных вузов, что повысит точность прогнозов. Особое внимание уделяется разработке специализированной методики формирования признаков, предназначенной именно для работы с образовательными данными. Практическим результатом станет интеграция этой модели в прототип веб-сервиса с интуитивно понятным интерфейсом, доступным для конечных пользователей. Кроме того, будет проведен сравнительный анализ эффективности различных алгоритмов машинного обучения в рамках этой предметной области, что позволит выбрать наиболее подходящий инструмент.

В основе исследования лежит гипотеза о существовании устойчивой зависимости между вероятностью зачисления абитуриента на бюджетное место и определенной комбинацией факторов. К ним относятся не только академические показатели, такие как баллы ЕГЭ и средний балл аттестата, но и индивидуальные достижения, исторические данные о конкурсной ситуации на конкретном направлении, а также параметры самого образовательного направления. Предполагается, что эта скрытая зависимость может быть выявлена и верифицирована с помощью методов машинного обучения с уровнем точности, достаточным для практического применения в реальных условиях.

Целью работы является разработка аналитической системы для оценки вероятности зачисления абитуриента на бюджетное место в вузе и создание на ее основе работоспособного прототипа веб-сервиса.

Для достижения поставленной цели необходимо решить следующие задачи:

* Провести анализ предметной области и систематизировать ключевые факторы, влияющие на процедуру зачисления.
* Осуществить сбор и подготовку ретроспективных данных о подаче документов и зачислении абитуриентов.
* Разработать и реализовать методику формирования и отбора признаков для построения прогнозной модели.
* Провести обучение, сравнительную оценку и выбор оптимальной модели машинного обучения.
* Разработать функциональный прототип веб-сервиса, интегрирующий выбранную модель.
* Выполнить валидацию системы и проанализировать значимость факторов для итогового прогноза.

**1.** **АНАЛИЗ И ПРОЕКТИРОВАНИЕ ЦИФРОВОГО ПОМОЩНИКА СОТРУДНИКА ПРИЁМНОЙ КОМИССИИ**

**1.1 Анализ предметной области и ключевых факторов зачисления в вузы**

Процесс приема в высшие учебные заведения Российской Федерации представляет собой сложную, регламентированную и высоко конкурентную систему. Ежегодно более миллиона абитуриентов подают документы на ограниченное количество бюджетных мест, что создает значительную нагрузку как на самих поступающих, так и на сотрудников приемных комиссий [14]. Основная проблема для абитуриента заключается в стратегическом выборе направлений подготовки и вузов, который максимизирует его шансы на зачисление на желаемую специальность и форму обучения (бюджет/контракт).

Ключевым документом, регулирующим этот процесс, является «Порядок приема на обучение по образовательным программам высшего образования» [1], устанавливающий этапы зачисления: первоочередное (для льготных категорий), основное и дополнительное. В рамках этого процесса формируются конкурсные списки (рейтинги), где абитуриенты ранжируются по сумме набранных баллов.

Анализ предметной области позволяет выделить следующие критически важные факторы, влияющие на вероятность зачисления абитуриента на бюджетное место:

1. Академические показатели:

* Сумма баллов ЕГЭ: Является первичным и основным критерием для включения в конкурсный список. Прямо определяет позицию абитуриента в рейтинге.
* Результаты по профильным предметам: Для некоторых технических или творческих специальностей баллы по конкретным предметам (например, математика, физика) могут иметь повышенный вес или быть пороговым значением.
* Средний балл аттестата: Учитывается при равенстве суммы баллов ЕГЭ с другими абитуриентами.

1. Индивидуальные достижения (ИД):

* Наличие статуса победителя или призера всероссийских олимпиад школьников, дающих право на зачисление без вступительных испытаний (БВИ).
* Наличие золотого знака ГТО, аттестата с отличием, волонтерской книжки и других достижений, за которые начисляются дополнительные баллы (до 10 включительно). Эти баллы суммируются с результатами ЕГЭ и могут существенно повлиять на позицию в рейтинге.

1. Конкурсная ситуация и исторические данные:

* Проходной балл прошлых лет: Является ориентиром, но не абсолютным показателем, так как может колебаться в зависимости от спроса, количества поданных заявлений и среднего уровня подготовки абитуриентов в текущем году.
* Количество поданных заявлений (конкурс на место): Прямо указывает на уровень конкуренции на конкретном направлении.
* Количество бюджетных мест: Динамический параметр, который может меняться от года к году.
* Динамика изменения проходного балла: Позволяет выявить тренды — рост или снижение популярности направления.

1. Поведенческие факторы абитуриента:

* Количество и приоритетность выбранных направлений в рамках одного вуза: Абитуриент может подать заявление на несколько направлений, указав приоритет. Алгоритм зачисления учитывает этот приоритет, что создает сложную зависимость.
* Подача документов в несколько вузов: Успешный абитуриент может быть зачислен в другой вуз, освобождая место в рейтинге следующему за ним. Этот фактор вносит значительную неопределенность в прогноз.

1. Контекстуальные факторы направления и вуза:

* Престиж и рейтинг вуза.
* Региональная расположенность.
* Популярность и востребованность специальности на рынке труда.

Таким образом, задача прогнозирования вероятности зачисления является задачей классификации с множеством взаимосвязанных признаков, где целевой переменной является бинарный исход: «зачислен» / «не зачислен». Понимание этих факторов является основой для следующего этапа — формализации задачи и сбора релевантных данных для построения прогнозной модели.

**1.2 Обзор алгоритмов машинного обучения для задач классификации**

Для решения задачи бинарной классификации, подобной задаче прогнозирования зачисления, существует широкий спектр алгоритмов машинного обучения. Выбор оптимального алгоритма зависит от объема и качества данных, интерпретируемости модели и требуемой точности. Рассмотрим наиболее подходящих кандидатов, которые представлены в таблице 1.1.

Таблица 1.1 – Сравнительный обзор алгоритмов классификации

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Алгоритм | Принцип работы | Преимущества | Недостатки | Применимость к задаче |
| Логистическая регрессия | Моделирует вероятность с помощью логистической функции. | Высокая интерпретируемость, устойчивость к шуму. | Предполагает линейную зависимость. | Базовый, интерпретируемый вариант. |
| Метод опорных векторов (SVM) | Ищет разделяющую гиперплоскость с максимальным зазором. | Эффективен в пространствах высокой размерности. | Плохо масштабируется, требует настройки ядра. | При наличии четкой границы между классами. |
| Деревья решений | Строит древовидную структуру с проверками условий. | Простота визуализации, работа с нелинейными зависимостями. | Склонность к переобучению, неустойчивость. | Основа для ансамблевых методов. |
| Случайный лес (Random Forest) | Ансамбль независимых деревьев, прогноз по голосованию. | Высокая точность, устойчивость к переобучению и шуму. | Сложность интерпретации («чёрный ящик»). | **Высокая.** Эффективен для табличных данных. |
| Градиентный бустинг (XGBoost, CatBoost) | Последовательное построение деревьев, исправляющих ошибки. | Наивысшая точность, эффективная обработка данных. | Сложность настройки, риск переобучения. | **Высокая.** Часто лидирует по качеству. |
| Нейронные сети | Многослойные структуры для поиска сложных паттернов. | Высокая способность к аппроксимации. | Требуют больших данных, низкая интерпретируемость. | При очень больших и сложных наборах данных. |

Для данной задачи наиболее перспективными представляются алгоритмы логистической регрессии (как базовый и интерпретируемый вариант) и ансамбли на основе деревьев, такие как Random Forest и XGBoost, которые, как показывает практика, часто показывают высокое качество на табличных данных, к которым относятся данные о поступлении.

**1.3 Методологии разработки программных систем и жизненные циклы Data Science – проектов**

Разработка цифрового помощника сотрудника приемной комиссии (ЦПСТ) находится на стыке двух дисциплин: классической разработки программного обеспечения (Software Engineering) и Data Science. Поэтому для успешной реализации проекта необходимо комбинировать подходы из обеих областей. Рассмотрим основные методологии разработки программного обеспечения:

1. Гибкие методологии (Agile), в частности Scrum:

* Применение: Идеально подходит для итеративной разработки прототипа веб-сервиса. Проект разбивается на короткие спринты (1-2 недели), по итогу каждого из которых создается работающий инкремент продукта. Например, в первом спринте — сбор данных, во втором — EDA, в третьем — обучение базовой модели и т.д.
* Преимущества: Позволяет быстро адаптироваться к изменениям требований, получать обратную связь на ранних этапах и непрерывно улучшать продукт.

1. Канбан:

* Применение: Эффективен для управления задачами на этапе поддержки и доработки модели (например, регулярное обновление данных и переобучение). Визуализация потока работ (To Do, In Progress, Done) помогает контролировать прогресс.

Наиболее распространенной и адекватной методологией для проектов, связанных с данными и машинным обучением, является CRISP-DM (Cross-Industry Standard Process for Data Mining). Этот процесс состоит из шести взаимосвязанных этапов:

1. Бизнес-понимание (Business Understanding):

* Цель: Полное понимание целей проекта и требований с точки зрения бизнеса (в нашем случае — потребностей приемной комиссии и абитуриентов).
* Результаты: Постановка задачи, определение критериев успеха, формулировка гипотез.

1. Понимание данных (Data Understanding):

* Цель: Сбор исходных данных и их первоначальное исследование.
* Результаты: Описательная статистика, выявление аномалий и пропусков, первичные визуализации (EDA).

1. Подготовка данных (Data Preparation):

* Цель: Преобразование сырых данных в чистый датасет, пригодный для машинного обучения.
* Результаты: Очистка данных, обработка пропусков и выбросов, кодирование категориальных признаков, создание новых признаков (Feature Engineering), нормализация и масштабирование. Этот этап часто является самым трудоемким.

1. Моделирование (Modeling):

* Цель: Подбор и обучение различных моделей машинного обучения.
* Результаты: Обученные модели, подобранные гиперпараметры. На этом этапе данные обычно разделяются на обучающую, валидационную и тестовую выборки.

1. Оценка (Evaluation):

* Цель: Определение того, насколько хорошо модель удовлетворяет бизнес-требованиям, и проверка ее надежности.
* Результаты: Расчет метрик качества (Accuracy, Precision, Recall, F1-score, ROC-AUC), сравнение моделей между собой, проверка на тестовой выборке, которую модель не видела ранее.

1. Внедрение (Deployment):

* Цель: Интеграция модели в рабочую среду, чтобы она могла приносить практическую пользу.
* Результаты: Работающий прототип веб-сервиса, API для модели, документация.

Важно отметить, что CRISP-DM является итеративным процессом. Результаты этапа оценки могут потребовать возврата к подготовке данных для создания новых признаков или даже к пересмотру гипотез на этапе бизнес-понимания.

Для данного проекта предлагается использовать гибридный подход. Общее управление проектом и разработка веб-интерфейса ведутся по принципам Scrum. Внутри каждого спринта, связанного с работой с данными и ML, этапы выполняются в соответствии с CRISP-DM. Это обеспечивает гибкость управления и в то же время структурную четкость в решении аналитических задач.

**2. РАЗРАБОТКА АЛГОРИТМА ПРОГНОЗИРОВАНИЯ ВЕРОЯТНОСТИ ЗАЧИСЛЕНИЯ**

**2.1 Постановка задачи**

В рамках проектирования цифрового помощника сотрудника приемной комиссии (ЦПСТ) была сформулирована ключевая задача — создание прогнозной аналитической системы. Целью системы является оценка вероятности зачисления конкретного абитуриента на бюджетное место по выбранному им направлению подготовки. Данная задача имеет высокую практическую значимость, так как позволяет формализовать процесс принятия решений и снизить неопределенность для всех участников приемной кампании.

С математической точки зрения задача определена как задача бинарной классификации. Целевая переменная y принимает два значения: 1 (абитуриент зачислен на бюджетное место) и 0 (абитуриент не зачислен). Таким образом, необходимо построить функцию отображения f: X → Y, где X — это многомерное пространство признаков, характеризующих абитуриента и контекст его выбора (академические показатели, приоритет, конкурсная ситуация и др.), а Y — это вероятность принадлежности к положительному классу, то есть интервал [0, 1]. Функция f должна аппроксимировать истинную, но неизвестную зависимость между характеристиками абитуриента и исходом его поступления.

Установлены критерии качества модели:

* ROC-AUC (Area Under Curve) ≥ 0.85 — интегральный показатель качества ранжирования [3].
* Precision (Точность) ≥ 0.80 — доля верно предсказанных поступивших среди всех, кому модель предсказала поступление.
* Recall (Полнота) ≥ 0.75 — доля верно предсказанных поступивших среди всех фактически поступивших.

**2.2. Сбор, фильтрация и предварительный анализ данных о поступлении в вуз абитуриентов**

Качество любой прогнозной модели напрямую зависит от объема, релевантности и чистоты исходных данных. В рамках данного проекта был организован процесс сбора информации из нескольких взаимодополняющих источников. Основу составили архивные электронные конкурсные списки университета, охватывающие десятилетний период с 2014 по 2024 год. Эти данные содержали детальную информацию о каждом абитуриенте, подававшем заявление, включая его позицию в рейтинге и финальный статус. Для обогащения набора признаков и верификации были использованы интегрированные данные, полученные путём парсинга портала «Госуслуги», которые предоставили дополнительные сведения об абитуриентах. Третий источник — внутренняя нормативно-справочная информация университета — использовался для корректной интерпретации кодов направлений подготовки, количества бюджетных мест и других административных параметров.

В результате консолидации был сформирован массив данных, содержащий приблизительно 85 000 записей, каждая из которых соответствует одной подаче заявления. Структура записи включала несколько смысловых блоков: демографические данные (пол, регион проживания), академические показатели (баллы ЕГЭ по трем-четырем предметам, средний балл аттестата), параметры выбора (код и название направления подготовки, указанный приоритет этого направления в заявлении), информацию об индивидуальных достижениях (начисленные дополнительные баллы) и, что наиболее важно, финальный результат — факт зачисления абитуриента на бюджетное место по данному направлению.

Полученный сырой массив данных требовал тщательной предобработки перед использованием в модели. Процесс очистки и фильтрации включал несколько этапов. В первую очередь была проведена очистка от технических аномалий и ошибок ввода: из выборки удалены записи, содержащие некорректные значения баллов ЕГЭ (менее 20 или более 100). Для числовых признаков, таких как средний балл аттестата, в которых встречались пропущенные значения, была применена стратегия заполнения медианным значением по соответствующему направлению подготовки, что является более устойчивым к выбросам методом по сравнению с заполнением общим средним. Далее осуществлена консолидация и нормализация данных: информация из разных источников и за разные годы была приведена к единой структуре с использованием унифицированных справочников (например, для кодов направлений). На заключительном этапе фильтрации были исключены записи с неполным набором критически важных признаков, без которых построение прогноза невозможно.

В ходе предварительного анализа были выявлены ключевые проблемы, потребовавшие специальных подходов на этапе моделирования. Наиболее существенной из них оказался сильный дисбаланс классов в целевой переменной: только около 20% записей (17 000) соответствовали положительному исходу («зачислен»), в то время как 80% (68 000) — отрицательному («не зачислен»). Такое соотношение 1:4 является типичным для конкурсных процедур, но создает риск того, что модель, оптимизирующая общую точность, будет «игнорировать» миноритарный класс. Другими вызовами стали неоднородность форматов хранения данных за разные годы (что потребовало разработки скриптов - трансформеров) и различия в системах кодирования направлений подготовки, которые были стандартизированы. Выявление и осознание этих проблем на раннем этапе позволило грамотно спланировать дальнейшие шаги по разработке модели, включая применение методов борьбы с дисбалансом и тщательный инжиниринг признаков.

**2.3 Проектирование и создание признаков (Feature Engineering) для модели прогнозирования вероятности поступления**

Процесс Feature Engineering являлся ключевым этапом в разработке модели, поскольку исходные данные требовали значительной трансформации для раскрытия скрытых закономерностей и повышения прогнозной силы алгоритма.

При анализе и подготовки исходных признаков, исходный набор данных содержал следующие сырые признаки (перечислены только самые значимые):

1. Категориальные: пол, направление, приоритет, регион, тип поселения.
2. Числовые: баллы за предметы ЕГЭ, дополнительные баллы, средний балл аттестата.

Первичный анализ показал, что многие признаки демонстрируют нелинейную зависимость от целевой переменной, а также существуют сложные взаимодействия между ними, что потребовало создания дополнительных синтетических признаков.

Для повышения эффективности прогнозной модели был создан комплекс производных признаков, которые можно разделить на несколько тематических групп.

Агрегированные признаки позволяют оценить общий уровень подготовки абитуриентов и сбалансированность его знаний по разным предметам. К ним относятся:

1. Суммарный балл ЕГЭ рассчитывается по формуле (1), данный показатель служит базовой характеристикой академической подготовки абитуриента.

|  |  |
| --- | --- |
|  | (1) |
| – суммарный балл ЕГЭ | |
| – балл за *i* – й предмет ЕГЭ | |

1. Итоговый конкурсный балл – является ключевым при формировании рейтинга абитуриента, рассчитывается по формуле (2).

|  |  |
| --- | --- |
|  | (2) |
| – итоговый конкурсный балл | |
| – суммарный балл ЕГЭ | |
| – дополнительные баллы за индивидуальные достижения | |

1. Для оценки вариации по разным предметам используя формулы (3), (4) и (5).

|  |  |
| --- | --- |
|  | (3) |
|  | (4) |
|  | (5) |
| – максимальный балл по предметам ЕГЭ | |
| - минимальный балл по предметам ЕГЭ | |
| – разброс между баллами ЕГЭ, характеризующий равномерность подготовки абитуриента | |
| – балл за *i* – й балл ЕГЭ | |

Признаки эффективности характеризуют относительные показатели успешности абитуриента. Эффективность ЕГЭ отражает долю реализованного потенциала и рассчитывается как отношение суммарного балла ЕГЭ к максимально возможному. Соответствие аттестата баллам ЕГЭ показывает согласованность результатов итоговой школьной аттестации и экзаменационных показателей. Доля дополнительных баллов демонстрирует вклад индивидуальных достижений в общий конкурсный балл. Ниже представлены формулы для расчёта эффективности (6), соответствия аттестата баллам ЕГЭ (7) и доля дополнительных баллов (8).

|  |  |
| --- | --- |
|  | (6) |
| – эффективность ЕГЭ | |
| – суммарный балл ЕГЭ | |
| – количество предметов | |
|  | (7) |
| – соответствие аттестата баллам ЕГЭ | |
| – средний балл аттестата | |
| – эффективность ЕГЭ | |
|  | (8) |
| – доля дополнительных баллов | |
| – дополнительные баллы | |
| – итоговый конкурсный балл | |

Комбинаторные признаки включают определение профиля абитуриента по совокупности результатов ЕГЭ. На основе анализа комбинации сданных предметов и полученных баллов абитуриенты классифицируются по профилям: технический, гуманитарный, естественно-научный, универсальный.

Признаки относительного позиционирования позволяют оценить позицию абитуриента относительно других поступающих на то же направление. Относительный балл представляет собой Z-score в рамках направления и показывает, насколько результат абитуриента отклоняется от среднего по направлению (9). Позиция в нормализованном рейтинге характеризует место абитуриента в общем списке поступающих (10).

|  |  |
| --- | --- |
|  | (9) |
| – относительный балл (Z-score) | |
| – итоговый конкурсный балл конкретного абитуриента | |
| **– средний балл на направление** | |
| **– стандартное отклонение среднего балла на направление** | |
|  | (10) |
| – позиция в условном рейтинге | |
| – общее число абитуриентов на направление в выборке | |
| – текущая позиция абитуриента в рейтинге (где 1 – лучшая, N – худшая) | |

Историко-контекстуальные признаки учитывают динамику популярности направлений и временные факторы. Исторический проходной балл представляет собой средний проходной балл на направление за последние 3 года (11). Конкурс на место отражает количество поданных заявлений на одно бюджетное место в текущем году (12). Тренд популярности показывает изменение конкурсной ситуации по сравнению с предыдущим годом (13). Сезонность подачи документов по периоду подачи: ранний, основной, поздний.

|  |  |
| --- | --- |
|  | (11) |
| – средний проходной балл на направление за последние 3 года | |
| – проходной балл на направление подготовки | |
| – индекс года в выборке | |
|  | (12) |
| - конкурс на место | |
| – количество поданных заявлений на направление | |
| – количество бюджетных мест на направление | |
|  | (13) |
| – тренд популярности направления подготовки | |
| – конкурс на место в текущем году | |
| – конкурс на место в предыдущем году | |

Всего в результате Feature Engineering было создано 22 новых признака, которые значительно расширили прогнозный потенциал исходного набора данных и позволили более точно выявлять сложные зависимости между характеристиками абитуриентов и вероятностью их зачисления.

Для преобразования категориальных переменных в числовой формат, пригодный для обучения моделей машинного обучения, была применена комбинированная стратегия. Выбор конкретного метода кодирования основывался на природе данных, кардинальности признака (количестве уникальных категорий) и необходимости сохранить или исключить семантику порядка.

Порядковое кодирование (Ordinal Encoding) было применено к признакам, обладающим естественной и содержательной порядковой зависимостью. В частности, переменная «Приоритет», принимающая значения 1, 2 и 3, напрямую отражает ранжирование выборов абитуриента, где первый приоритет является наиболее значимым. Аналогично, признак «Уровень конкурса» с категориями «низкий», «средний», «высокий» также подразумевает строгую градацию интенсивности конкуренции. Использование порядкового кодирования позволило сохранить эту важную для модели порядковую информацию, заменив строковые значения на соответствующие целочисленные ранги.

Прямое кодирование (One-Hot Encoding, OHE) было выбрано для номинальных признаков, категории которых не несут внутреннего порядка и являются взаимоисключающими. Данный метод преобразует каждую категорию в отдельный бинарный признак (столбец), принимающий значение 1, если наблюдение принадлежит к этой категории, и 0 в противном случае. Это предотвратило введение в модель ложных порядковых отношений. OHE был применен к бинарному признаку «Пол» (мужской/женский) и к мультиклассовым признакам, таким как «Комбинация предметов ЕГЭ» (например, math\_physics\_russian, math\_cs\_russian). Для признака «Регион», обладающего высокой кардинальностью, чтобы избежать чрезмерного роста размерности данных и связанного с этим переобучения, OHE был применен только к основным регионам (Приложение Б), представленным в выборке более чем 100 абитуриентами. Остальные регионы были сгруппированы в общую категорию «Прочие».

Целевое кодирование (Target Encoding) стало оптимальным решением для обработки признаков с высоким кардинальным числом категорий, где применение OHE было бы неэффективно. При этом методе каждая категория заменяется статистикой, рассчитанной на основе целевой переменной — в данном случае, средней вероятностью зачисления. Например, для признака «Направление подготовки» каждому коду направления было присвоено значение, равное историческому проценту поступивших абитуриентов на это направление. Аналогично, для «Профиля абитуриента» вычислялась агрегированная вероятность поступления для всех абитуриентов данного профиля. Для борьбы с утечкой данных и повышения устойчивости к редко встречающимся категориям, при вычислении среднего использовалась сглаживающая регуляризация по формуле Лапласа, которая учитывает глобальное среднее значение целевой переменной.

Предобработка числовых признаков проводилась с целью обеспечения устойчивости моделей к выбросам и приведения распределений к более симметричному виду. Для основных экзаменационных баллов (ЕГЭ по предметам) был применен метод Winsorization, при котором значения, выходящие за границы 1-го и 99-го перцентилей, были принудительно ограничены этими пороговыми значениями. Это позволило смягчить влияние аномально высоких или низких оценок без полного удаления записей. Для производных признаков, таких как «Разброс баллов ЕГЭ» или «Исторический конкурс», распределения которых часто имеют выраженную правостороннюю асимметрию, использовалось логарифмическое преобразование (после сдвига на +1 для обработки нулевых значений). Это преобразование существенно уменьшило скошенность распределения, что благоприятно для многих алгоритмов машинного обучения, особенно линейных.

Отбор наиболее значимых признаков стал заключительным этапом подготовки данных. После процедур Feature Engineering и кодирования размерность пространства признаков превысила 50 переменных, что создавало риск переобучения и увеличения вычислительной сложности. Для выявления наиболее информативного подмножества признаков был использован комплексный подход. Во-первых, была оценена важность признаков (Feature Importance) с помощью предварительно обученной модели Random Forest, которая ранжирует признаки по их вкладу в снижение энтропии при разбиениях в деревьях. Во-вторых, был вычислен показатель взаимной информации (Mutual Information) между каждым признаком и целевой переменной, что позволило оценить нелинейную статистическую зависимость. В-третьих, был применен итеративный алгоритм рекурсивного исключения признаков (Recursive Feature Elimination, RFE), который последовательно удаляет наименее значимые признаки на основе весов, полученных от базового классификатора (логистической регрессии). На основе консенсуса этих трех методов был сформирован финальный набор из 22 наиболее релевантных и информативных признаков, который и использовался для обучения итоговых моделей.

Качество отобранного набора признаков было проверено с помощью комплекса методов:

1. Анализ корреляционной матрицы — позволил идентифицировать и исключить сильно коррелирующие (мультиколлинеарные) признаки, что повысило стабильность модели.
2. Визуализация распределений — использовалась для проверки разделительной способности признаков относительно целевого класса (поступил/не поступил).
3. Сравнительный анализ метрик — эффективность инженерных решений оценивалась путем сравнения ключевых метрик (ROC-AUC, F1-score) на валидационной выборке до и после проведения Feature Engineering.

Применение комплексного подхода к проектированию и отбору признаков позволило существенно повысить предсказательную способность модели. Значение метрики ROC-AUC увеличилось с 0.84 до 0.91, что подтверждает эффективность выбранных методов. Для обеспечения воспроизводимости и операционного развертывания весь процесс обработки данных был инкапсулирован в единый конвейер с использованием библиотеки scikit-learn.

**2.4 Обучение и сравнительный анализ моделей машинного обучения**

Перед началом процесса обучения моделей необходимо было решить две ключевые организационные задачи: устранение дисбаланса классов в данных и корректное разделение выборки для обеспечения надежной оценки обобщающей способности алгоритмов.

Решение проблемы дисбаланса классов. Исходное распределение целевой переменной демонстрировало значительный перекос: класс «не зачислен» был представлен примерно в четыре раза чаще, чем класс «зачислен». Такая ситуация могла привести к тому, что модели, оптимизирующие общую точность, стали бы предсказывать мажоритарный класс в ущерб способности корректно идентифицировать абитуриентов, которые реально поступят. Для устранения этого перекоса был применен метод SMOTE. Его ключевая идея заключается в генерации синтетических примеров для миноритарного класса, а не в простом дублировании существующих. SMOTE работает путем выбора случайного объекта из миноритарного класса, нахождения его k ближайших соседей из того же класса и создания новых точек на отрезках, соединяющих выбранный объект с его соседями. В данной работе использовалась реализация SMOTE из библиотеки imbalanced-learn со значением параметра k\_neighbors=5. Это позволило сбалансировать количество примеров в обоих классах на этапе обучения, не затрагивая валидационную и тестовую выборки, что критически важно для получения объективной оценки.

Подготовка и разделение данных. После балансировки миноритарного класса данные были разделены на три непересекающихся подмножества. Использовалась стратифицированная разбивка, которая сохраняет исходное процентное соотношение классов в каждой из выборок. Это гарантирует, что как в обучающей, так и в тестовой частях будет представлена одинаковая пропорция положительных и отрицательных примеров. Общий объем данных был распределен следующим образом: 70% составила обучающая выборка, использовавшаяся непосредственно для подстройки параметров моделей; 15% — валидационная выборка, применяемая для тонкой настройки гиперпараметров и предотвращения переобучения; и оставшиеся 15% — тестовая выборка, которая полностью изолирована от процесса обучения и служит для финальной, объективной оценки качества выбранной модели. Такое разделение соответствует лучшим практикам в машинном обучении.

Выбор и обучение сравниваемых моделей. Для решения задачи бинарной классификации были отобраны три алгоритма, представляющие различные парадигмы машинного обучения, что позволяет комплексно оценить природу данных.

* 1. Логистическая регрессия была выбрана в качестве простого, быстрого и высоко интерпретируемого базового алгоритма. Её линейная природа позволяет легко анализировать влияние каждого признака на итоговый прогноз. Для нелинейных зависимостей использовалось ядро RBF.
  2. Случайный лес (Random Forest) — ансамблевый метод, построенный на множестве решающих деревьев. Его ключевые преимущества — способность эффективно работать с нелинейными зависимостями и взаимодействиями признаков, устойчивость к переобучению (за счет бэггинга и случайного выбора признаков) и встроенная оценка важности признаков.
  3. Многослойный перцептрон (нейронная сеть) был взят как представитель глубокого обучения. Архитектура сети состояла из трех полносвязных скрытых слоев (128, 64 и 32 нейрона) с функциями активации ReLU, что позволяет модели автоматически извлекать сложные иерархические признаки из данных.

Обучение каждой модели проводилось на сбалансированной обучающей выборке. Для случайного леса и нейронной сети была выполнена настройка гиперпараметров с помощью поиска по сетке (GridSearchCV) на валидационной выборке. Для случайного леса оптимизировались количество деревьев, максимальная глубина и минимальное число образцов в листе. Для нейронной сети подбирались скорость обучения и коэффициент регуляризации.

Сравнительный анализ результатов. Финальная оценка всех трех моделей была проведена на независимой тестовой выборке, которая не участвовала ни в обучении, ни в валидации. Основными метриками сравнения выступили ROC-AUC (характеризует общее качество ранжирования), F1-мера (гармоническое среднее между точностью и полнотой) и точность (Accuracy). Сводные результаты представлены в таблице 1.

Таблица 2.1 – Сравнение результатов моделей на тестовой выборке

|  |  |  |  |
| --- | --- | --- | --- |
| Модель | ROC-AUC | F1-Score | Accuracy |
| Случайный лес | 0.91 | 0.82 | 0.83 |
| Логистическая регрессия | 0.81 | 0.75 | 0.74 |
| Нейронная сеть | 0.79 | 0.74 | 0.75 |

Как видно из таблицы, наилучшие показатели по всем ключевым метрикам продемонстрировала модель случайного леса, достигнув значения ROC-AUC 0.91. Это свидетельствует о её высокой способности различать классы. Логистическая регрессия, обладая максимальной интерпретируемостью, показала более низкий результат (ROC-AUC 0.81), что косвенно подтверждает наличие в данных сложных нелинейных взаимосвязей, которые линейная модель не может адекватно описать. Нейронная сеть показала хороший результат (ROC-AUC 0.79), близкий к логистической регрессии, однако её обучение потребовало значительно больше вычислительных ресурсов и времени, а итоговая модель является «черным ящиком», что затрудняет её анализ и объяснение прогнозов. Учитывая наивысшее качество, устойчивость и относительную простоту интерпретации (через важность признаков), для интеграции в прототип цифрового помощника была выбрана модель случайного леса.

**3. Внедрение цифрового помощника сотрудника приёмной комиссии**

**3.1 Валидация моделей и выбор оптимальной по метрикам качества**

Процедура валидации спроектированной модели носила комплексный характер и состояла из нескольких взаимодополняющих этапов, направленных на всестороннюю оценку как статистического качества, так и практической применимости в реальных условиях работы приёмной комиссии. Для тестирования были выделены следующие этапы:

1. Тестирование на hold-out выборке 2024 года. Эта выборка не участвовала ни на одном из предыдущих этапов и служила для получения объективной оценки обобщающей способности модели.
2. Проверка устойчивости модели на подвыборках разных лет. Для этого создавались подвыборки по каждому году из доступного десятилетнего периода (2014-2023 гг.), и модель оценивалась на данных, относящихся к тем годам, которые не входили в её обучающий набор. Такой подход позволил убедиться в стабильности качества прогноза в условиях, меняющихся с течением времени образовательных трендов и конкурсных ситуаций.
3. Анализ кривых обучения и валидации (представлен в приложении X)
4. Проверка результатов на адекватность с помощью предметных экспертов – сотрудников приёмной комиссии. Сотрудникам были предоставлены предсказания модели для анонимизированной выборки абитуриентов прошедших лет. Эксперты оценивали логичность и адекватность прогнозов с точки зрения своего практического опыта, отмечая, что модель корректно учитывает ключевые факторы, такие как итоговый балл и приоритетность заявления.
5. Тестирование на данных из конкурсных списков 2025 года. Модель успешно обработала новые данные, а её предварительные прогнозы по текущим абитуриентам были признаны экспертами логичными и обоснованными.

Модель случайного леса показала наилучшие показатели как на итоговых метриках, так и по результатам комплексной валидации. Также помимо наивысшей дискриминационной способности (ROC-AUC 0.91), модель продемонстрировала оптимальный баланс между точностью и полнотой, что критически важно для практического применения: система не должна создавать излишне завышенные ожидания (низкая precision) или, наоборот, упускать реальных кандидатов (низкий recall). Устойчивость к переобучению, обеспечиваемая механизмами бэггинга и случайного выбора признаков в алгоритме Random Forest, была подтверждена кривыми обучения. Наконец, модель обладает относительно высокой интерпретируемостью за счёт возможности анализа важности признаков (Feature Importance), что позволяет не только выдавать прогноз, но и объяснять, какие факторы на него повлияли. Это выгодно отличает её от нейронных сетей и превосходит по качеству линейные модели, неспособные уловить сложные нелинейные зависимости в данных.

**3.2** **Разработка и тестирование прототипа веб-интерфейса для оценки шансов поступления**

Для практического внедрения результатов исследования была разработан микро-сервис для развёртывания ML модели, интегрирующийся в микро-сервисную архитектуру ЦПСПК. Архитектура решения построена по принципу разделения ответственности и включает три ключевых компонента (Приложение X).

Сервис ML модели: Ядро системы реализовано в виде автономного stateless-микросервиса на Python. В качестве веб-фреймворка выбран FastAPI [9] благодаря его высокой производительности, автоматической генерации документации OpenAPI и удобству работы с типами данных (через Pydantic). Вся логика предобработки входных данных (кодирование, масштабирование) и сам алгоритм Random Forest инкапсулированы в единый scikit-learn Pipeline, который был сериализован с помощью joblib. Это гарантирует, что процесс преобразования данных на этапе эксплуатации в точности повторяет процесс, использованный при обучении. Сервис предоставляет единственный эндпоинт POST /predict (представлен в приложении X), который принимает JSON-объект с характеристиками абитуриента и направления, а возвращает расчётную вероятность поступления и бинарный класс. Stateless-природа сервиса позволила эффективно масштабировать его: в Docker-контейнере запускается несколько воркеров Uvicorn, что повышает пропускную способность в условиях потенциально высокой нагрузки в период приёмной кампании.

Для взаимодействия с конечными пользователями — абитуриентами и сотрудниками приёмной комиссии — был разработан интуитивно понятный веб-интерфейс на современном стеке React JS. Интерфейс включает несколько ключевых экранов:

1. Калькулятор шансов: Форма с пошаговым заполнением полей (баллы ЕГЭ, средний балл аттестата, выбор направления и приоритета). Валидация данных происходит как на стороне клиента, так и на сервере.
2. Панель результатов: Наглядное отображение вероятности в виде процентной шкалы, цифрового значения и цветовой индикации (зелёный/жёлтый/красный).

Весь стек приложений упакован в Docker-контейнеры [13]. Сервис ML и веб-интерфейс описываются отдельными Dockerfile, что обеспечивает их независимое развёртывание и масштабирование. Для упрощения локального развёртывания и описания взаимодействий между сервисами используется docker-compose.yml. В производственной среде архитектура готова к развёртыванию в оркестраторе Kubernetes, где каждый микросервис может масштабироваться независимо в зависимости от нагрузки.

Процесс тестирования включал в себя несколько уровней. Первым этапом было проведено функциональное тестирование, которое включало в себя проверку работоспособности всех элементов интерфейса, отправки запросов к API и отображение результатов. Следующим шагом была произведена имитация пиковой нагрузки до 50 запросов в секунду на эндпоинт /predict, где сервис показал стабильную работу с медианным временем отклика 200 миллисекунд. Завершающим этапом тестирования была проверка краевых случаев, то есть проверка обработки некорректных или пропущенных данных, экстремально высоких или низких баллов, а также сценариев не покрытых обучающей выборкой.

**3.3 Интерпретация модели и анализ значимости факторов зачисления**

Для понимания логики, стоящей за прогнозами модели, и извлечения предметных знаний был проведён тщательный анализ важности признаков (Feature Importance) финальной модели Random Forest. Метод основан на оценке среднего уменьшения неопределенности (энтропии или коэффициента Джини) в каждом узле дерева при разбиении по конкретному признаку.

Количественный анализ выявил следующее распределение важности ключевых факторов:

1. Общий балл ЕГЭ (28%): Является абсолютно доминирующим фактором, что логично и соответствует официальной процедуре формирования рейтинга.
2. Направление подготовки (19%): Категориальный признак, отражающий специфику конкуренции, престижа и проходных баллов конкретной образовательной программы.
3. Приоритет заявления (15%): Высокая важность подтверждает стратегическое значение правильного выбора приоритета. Абитуриенты, указывающие направление первым приоритетом, имеют статистически значимо более высокие шансы на зачисление, что связано с алгоритмом прохождения по конкурсу.
4. Дополнительные баллы (12%): Существенный вклад свидетельствует о том, что индивидуальные достижения (олимпиады, ГТО, волонтёрство) часто становятся решающим фактором в условиях высокой конкуренции.
5. Средний балл аттестата (10%): Подтверждает корреляцию между долговременной успеваемостью в школе и успехом на ЕГЭ/в университете.
6. Прочие признаки (суммарно 16%): Включают комбинацию предметов, пол, исторический конкурс и другие факторы, оказывающие меньшее, но статистически значимое влияние.

Выводы, полученные в результате интерпретации модели, имеют практическую ценность для консультирования абитуриентов. Критичность суммарного балла подтверждает необходимость фокусироваться на максимальной подготовке к ЕГЭ как на основном стратегическом ресурсе. Высокая значимость приоритета делает процесс составления заявления не формальностью, а ключевым тактическим решением, требующим тщательного анализа. Вес дополнительных баллов является убедительным аргументом для мотивации школьников к участию в олимпиадах и социально значимой деятельности. Вариативность по направлениям подчёркивает, что шансы на поступление — это не абсолютная величина, а относительная, сильно зависящая от выбранной специальности и её текущей популярности.

Таким образом, модель не только предсказывает вероятность, но и структурирует факторы успеха, предоставляя основу для data-driven консультаций.

Основным ограничением текущей реализации является необходимость ежегодного обновления модели новыми данными для сохранения её актуальности. В качестве дальнейшего развития проекта планируется:

* Расширение аналитического функционала веб-интерфейса: дашборды для мониторинга хода приёмной кампании в реальном времени.
* Разработка RESTful API для интеграции системы с другими внутренними сервисами университета (например, с CRM или системой документооборота).
* Создание мобильного приложения, на основе существующего API для повышения доступности сервиса.

Таким образом, практическая часть работы демонстрирует полный жизненный цикл проекта — от постановки задачи и анализа данных до обучения модели и её внедрения в виде готового к использованию прототипа программного решения, что подтверждает достижение цели исследования.

**3.4 Результаты и метрики модели**

Итоговая модель Random Forest соответствует всем установленным критериям качества:

* ROC-AUC = 0.91 (требование: ≥ 0.85) (Приложение В).
* Precision = 0.83 (требование: ≥ 0.80).
* Recall = 0.81 (требование: ≥ 0.75).

Разработанный прототип веб-сервиса проходит полный цикл: от ввода данных абитуриента до вывода интерпретируемого прогноза.

**Заключение**

В ходе выполнения научно-исследовательской работы была достигнута поставленная цель — разработана аналитическая система для оценки вероятности зачисления абитуриента на бюджетное место в вузе и создан её функциональный прототип в виде цифрового помощника сотрудника приёмной комиссии (ЦПСПК).

Исследование подтвердило выдвинутую гипотезу о существовании устойчивой зависимости между комбинацией факторов (академические показатели, индивидуальные достижения, конкурсная ситуация, поведенческие параметры) и исходом поступления. В результате комплексного анализа предметной области были систематизированы ключевые факторы, влияющие на процедуру зачисления, что стало основой для формализации задачи машинного обучения.

В практической части работы был реализован полный цикл проекта Data Science: от сбора и очистки ретроспективных данных (архивы за 10 лет) до обучения, валидации и внедрения модели. Особое внимание было уделено процессу Feature Engineering, в ходе которого разработан и обоснован комплекс из 22 синтетических признаков. Это позволило трансформировать исходные данные и раскрыть скрытые закономерности, существенно повысив прогнозную силу алгоритмов. Проблема значительного дисбаланса классов была успешно решена применением передового метода SMOTE.

Проведённый сравнительный анализ моделей машинного обучения (логистическая регрессия, случайный лес, нейронная сеть) на тестовой выборке показал, что наилучшие результаты по совокупности метрик (ROC-AUC = 0.91, F1-Score = 0.82, Accuracy = 0.83) демонстрирует ансамблевый алгоритм Random Forest. Его выбор был обоснован не только высочайшей дискриминационной способностью и устойчивостью к переобучению, но и относительной интерпретируемостью, что критически важно для практического применения.

В рамках этапа внедрения была разработана микросервисная архитектура прототипа, включающая:

1. Backend-сервис на FastAPI, инкапсулирующий весь конвейер обработки данных и обученную модель.
2. Веб-интерфейс на React.js, предоставляющий интуитивный инструмент для ввода данных и визуализации прогноза.
3. Контейнеризованное развёртывание с использованием Docker, обеспечивающее переносимость, масштабируемость и устойчивость решения.

Анализ важности признаков итоговой модели предоставил ценные предметные инсайты, подтвердившие экспертные оценки: доминирующее влияние итогового балла ЕГЭ (28%), высокая значимость приоритета заявления (15%) и существенный вклад дополнительных баллов (12%). Это позволяет использовать систему не только для автоматического прогнозирования, но и для обоснованного консультирования абитуриентов на основе данных (data-driven counseling).

Научная новизна работы заключается в разработке специализированной методологии формирования признаков для образовательных данных, создании адаптивной модели, учитывающей региональные и вузовские особенности, и комплексной интеграции решения в прототип, готовый к опытной эксплуатации.

Практическая значимость результатов заключается в создании инструмента, который:

1. Для абитуриентов снижает неопределённость и позволяет оптимизировать стратегию подачи документов на основе персонализированного прогноза.
2. Для сотрудников приёмной комиссии автоматизирует рутинную аналитику, предоставляет инструмент для быстрой предварительной оценки и повышает качество консультаций.
3. Для вуза в целом способствует повышению эффективности и прозрачности приёмной кампании, а также улучшает удовлетворённость абитуриентов.

Таким образом, в работе решена актуальная научно-практическая задача, подтверждена эффективность выбранных методов машинного обучения для прогнозирования в образовательной сфере и продемонстрирован жизнеспособный прототип цифрового помощника, закладывающий основу для создания полноценной системы аналитической поддержки приёмной комиссии.

**Список используемых источников**

1. Приказ Минобрнауки России от 27.11.2024 N 821 "Об утверждении Порядка приема на обучение по образовательным программам высшего образования - программам бакалавриата, программам специалитета, программам магистратуры" (Зарегистрировано в Минюсте России 29.11.2024 N 80379) [Электронный ресурс]. –URL: <https://www.consultant.ru/document/cons_doc_LAW_491807/> (дата обращения 27.11.2025).
2. Géron, A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow / A. Géron. – 3rd ed. – O’Reilly Media, 2022. – 848 с.
3. Hastie, T., Tibshirani, R., Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction / T. Hastie, R. Tibshirani, J. Friedman. – 2nd ed. – Springer, 2017. – 764 с.
4. Chollet, F. Deep Learning with Python / F. Chollet. – 2nd ed. – Manning Publications, 2021. – 504 с.
5. Shearer, C. The CRISP-DM Model: The New Blueprint for Data Mining / C. Shearer // Journal of Data Warehousing. – 2000. – Vol. 5, No. 4. – P. 13-22.
6. Pedregosa, F. Scikit-learn: Machine Learning in Python / F. Pedregosa, G. Varoquaux, A. Gramfort et al. // Journal of Machine Learning Research. – 2011. – Vol. 12. – P. 2825-2830.
7. Chawla, N. V. SMOTE: Synthetic Minority Over-sampling Technique / N. V. Chawla, K. W. Bowyer, L. O. Hall et al. // Journal of Artificial Intelligence Research. – 2002. – Vol. 16. – P. 321-357.
8. Прохоров, А. В. Применение методов машинного обучения для прогнозирования поступления в вузы / А. В. Прохоров, И. С. Петрова // Информационные технологии в образовании. – 2022. – № 4(45). – С. 56-67.
9. FastAPI Documentation [Электронный ресурс]. – URL: <https://fastapi.tiangolo.com/> (дата обращения: 20.11.2025).
10. McKinney, W. Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter / W. McKinney. – 3rd ed. – O’Reilly Media, 2022. – 548 с.
11. Breiman, L. Random Forests / L. Breiman // Machine Learning. – 2001. – Vol. 45, No. 1. – P. 5-32.
12. Molnar, C. Interpretable Machine Learning: A Guide for Making Black Box Models Explainable / C. Molnar. – 2nd ed. – 2022 [Электронный ресурс]. – URL: <https://christophm.github.io/interpretable-ml-book/> (дата обращения: 12.11.2025).
13. Docker Documentation [Электронный ресурс]. – URL: <https://docs.docker.com/> (дата обращения: 18.11.2025).
14. Федеральная служба государственной статистики (Росстат). Образование в России: 2024 [Электронный ресурс]. – М., 2024. – URL: <https://rosstat.gov.ru/folder/210/document/13221> (дата обращения: 08.11.2025).

**Приложение A**

ЦПСПК – цифровой помощник сотрудника приёмной комиссии

ML – машинное обучение (с англ. Machine learning)

Feature Engineering – отбор значимых признаком для обучения модели.

Data Science – это междисциплинарная область, объединяющая статистику, математику, программирование и анализ данных для извлечения знаний из больших объемов информации.

Абитуриент – лицо, подающее заявление о приеме в образовательное учреждение высшего образования.

ROC-AUC (Area Under the Receiver Operating Characteristic Curve) – метрика, оценивающая способность модели к ранжированию объектов; площадь под кривой, характеризующей соотношение между истинно положительными и ложно положительными результатами при различных порогах классификации.

Precision (Точность) – метрика, показывающая долю правильно предсказанных положительных классов среди всех объектов, классифицированных моделью как положительные.

Recall (Полнота) – метрика, отражающая долю правильно предсказанных положительных классов среди всех объектов, фактически принадлежащих к положительному классу.

F1-Score – гармоническое среднее между точностью и полнотой, используемое для оценки сбалансированности модели.

Дисбаланс классов – ситуация в задачах классификации, когда примеры одного класса значительно превосходят по количеству примеры другого класса.

SMOTE (Synthetic Minority Over-sampling Technique) – алгоритм сэмплирования, предназначенный для увеличения количества примеров миноритарного класса путем создания синтетических объектов.

Feature Engineering (Конструирование признаков) – процесс создания новых признаков, на основе имеющихся данных с целью повышения качества машинного обучения.

One-Hot Encoding – метод кодирования категориальных переменных, при котором каждая категория преобразуется в отдельный бинарный признак.

Target Encoding – метод кодирования категориальных признаков, при котором каждая категория заменяется статистикой (например, средним значением целевой переменной) по этой категории.

Random Forest (Случайный лес) – ансамблевый алгоритм машинного обучения, строящий множество решающих деревьев и агрегирующий их предсказания.

Логистическая регрессия – статистическая модель, используемая для задач бинарной классификации, оценивающая вероятность принадлежности объекта к классу.

Микросервисная архитектура – подход к проектированию программного обеспечения как набора небольших независимых сервисов, взаимодействующих через API.

FastAPI – современный, быстрый веб-фреймворк для построения API на Python, поддерживающий автоматическую генерацию документации.

Docker – платформа для контейнеризации приложений, позволяющая упаковывать программное обеспечение и его зависимости в стандартизированные единицы.

CRISP-DM (Cross-Industry Standard Process for Data Mining) – межотраслевой стандартный процесс для анализа данных, описывающий жизненный цикл проектов машинного обучения.

EDA (Exploratory Data Analysis, Разведочный анализ данных) – начальный этап анализа данных, направленный на выявление закономерностей, аномалий и проверку гипотез с помощью статистических методов, и визуализации.

Конкурсный список – ранжированный перечень абитуриентов, подавших документы на конкретное направление подготовки, составленный по убыванию суммы конкурсных баллов.

Проходной балл – минимальный суммарный балл, с которым абитуриент был зачислен на бюджетное место по конкретному направлению в предыдущие годы.

БВИ (Без вступительных испытаний) – право на зачисление в вуз без прохождения конкурса, предоставляемое победителям и призерам определенных олимпиад школьников.

Индивидуальные достижения – дополнительные конкурсные баллы, начисляемые абитуриенту за успехи в учебе, спорте, волонтерской деятельности и др.

![](data:image/png;base64...)**Приложение Б**

Рисунок 1 – Скрипт One-Hot Encoding кодирования данных

![](data:image/png;base64...)**Приложение В**

Рисунок 2 – ROC-AUC кривая для случайного леса

![C:\Users\andre\Downloads\Telegram Desktop\photo_2025-12-05_13-49-39.jpg](data:image/jpeg;base64...)**Приложение Г**

Рисунок 3 – Форма для заполнения данных об абитуриенте

![C:\Users\andre\Downloads\Telegram Desktop\photo_2025-12-05_13-49-46.jpg](data:image/jpeg;base64...)

Рисунок 4 – Рекомендации направлений подготовки на основе вероятности поступления